{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train  = train_data.iloc[:, 0].values\n",
    "x_train = train_data.iloc[:, 1:].values    \n",
    "x_train = x_train.reshape(len(x_train), 32, 32)\n",
    "\n",
    "y_test  = test_data.iloc[:, 0].values\n",
    "x_test = test_data.iloc[:, 1:].values\n",
    "x_test = x_test.reshape(len(x_test), 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train), 32, 32, 1)\n",
    "x_test = x_test.reshape(len(x_test), 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80599 samples, validate on 14051 samples\n",
      "Epoch 1/10\n",
      "80599/80599 [==============================] - 51s 636us/step - loss: 1.2857 - acc: 0.6578 - val_loss: 0.4399 - val_acc: 0.8757\n",
      "Epoch 2/10\n",
      "80599/80599 [==============================] - 48s 599us/step - loss: 0.3959 - acc: 0.8842 - val_loss: 0.2625 - val_acc: 0.9244\n",
      "Epoch 3/10\n",
      "80599/80599 [==============================] - 46s 574us/step - loss: 0.2640 - acc: 0.9215 - val_loss: 0.2075 - val_acc: 0.9400\n",
      "Epoch 4/10\n",
      "80599/80599 [==============================] - 50s 619us/step - loss: 0.2016 - acc: 0.9386 - val_loss: 0.1664 - val_acc: 0.9512\n",
      "Epoch 5/10\n",
      "80599/80599 [==============================] - 47s 588us/step - loss: 0.1634 - acc: 0.9493 - val_loss: 0.1468 - val_acc: 0.9567\n",
      "Epoch 6/10\n",
      "80599/80599 [==============================] - 48s 595us/step - loss: 0.1357 - acc: 0.9577 - val_loss: 0.1399 - val_acc: 0.9593\n",
      "Epoch 7/10\n",
      "80599/80599 [==============================] - 44s 549us/step - loss: 0.1156 - acc: 0.9631 - val_loss: 0.1275 - val_acc: 0.9611\n",
      "Epoch 8/10\n",
      "80599/80599 [==============================] - 43s 535us/step - loss: 0.1023 - acc: 0.9671 - val_loss: 0.1212 - val_acc: 0.9651\n",
      "Epoch 9/10\n",
      "80599/80599 [==============================] - 48s 590us/step - loss: 0.0892 - acc: 0.9711 - val_loss: 0.1212 - val_acc: 0.9656\n",
      "Epoch 10/10\n",
      "80599/80599 [==============================] - 45s 559us/step - loss: 0.0808 - acc: 0.9733 - val_loss: 0.1115 - val_acc: 0.9674\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 58\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(x_train.shape[1], x_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200)\n",
    "#model.save('nepali_character_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.11151217748362283, 0.9674044551989183]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('nepali_character_recogintion_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
